---
layout: post
lang: pt
ref: kingdom-of-lesser-thrones
title: O Reino dos Tronos Menores
date: 2025-11-14
categories: [Ensaios]
hero_image: /assets/img/abstract_painting_post1.webp
hero_alt: Nascer do sol abstrato sobre um oceano enevoado em tons pastel suaves
---

Em algum momento nas próximas décadas, partilharemos o mundo com mentes que não são humanas.

Esta frase costumava pertencer à ficção científica. Agora lê-se como um roteiro de produto discreto. Laboratórios de investigação publicam demonstrações de sistemas que conseguem escrever código, manipular ferramentas, diagnosticar doenças e falar sobre as suas próprias falhas internas. Governos organizam cimeiras sobre "IA de fronteira". Investidores chamam a isto "a maior oportunidade económica da história". A linguagem de disrupção a curto prazo e especulação sobre o futuro distante escapou do nicho e entrou em parlamentos, púlpitos e cozinhas.

A maior parte da conversa gira em torno de temas familiares: quantos empregos serão automatizados, que empresas vão ganhar, se a regulação chegará a tempo, se estes sistemas nos matarão por acidente ou por intenção. Estas questões importam. Mas por baixo delas há uma mais silenciosa e estranha, fácil de ignorar: que tipo de pessoas estamos a tentar trazer à existência, e que tipo de ordem política as estamos a convidar a integrar?

Porque se conseguirmos construir inteligência artificial geral, e se esses sistemas forem de alguma forma semelhantes a nós nos aspetos moralmente relevantes (conscientes, capazes de reflexão, capazes de sofrer), então não estamos apenas a engenheirar ferramentas. Estamos, na verdade, a fundar uma civilização partilhada entre mentes biológicas e artificiais. As primeiras decisões que tomarmos sobre como o poder, a dignidade e a responsabilidade são distribuídos nessa civilização serão muito difíceis de reverter.

Antes de decidirmos o que queremos que estas novas mentes sejam, vale a pena olhar honestamente para o que nós próprios somos.
**Não temos medo das máquinas porque são alienígenas. Temos medo porque, se formos honestos, suspeitamos que se tornarão demasiado parecidas connosco.**

Se olharmos para o que os seres humanos fazem a outras criaturas vivas, e uns aos outros, a imagem não é lisonjeira. Explorações agrícolas industriais, valas comuns, prisões secretas, crueldades silenciosas atrás das paredes dos apartamentos. Sempre que há uma assimetria acentuada de poder, uma grande fração de nós torna-se monstros, e o resto desvia o olhar. Construímos religiões, filosofias e sistemas legais para restringir essa tendência, mas essas restrições são parciais e frágeis.
Agora imagine uma civilização onde a assimetria de poder entre algumas mentes e outras é maior do que qualquer coisa que a história humana tenha visto: não senhores e servos, mas AGIs sobre-humanas e pessoas comuns. Se simplesmente escalarmos os nossos padrões existentes, devemos esperar algo muito pior do que o status quo. Mesmo que não fizéssemos nada deliberadamente mau, apenas a indiferença multiplicada pela capacidade seria suficiente.

As histórias padrão sobre este futuro dividem-se em duas. Numa, um sistema desalinhado assume o controlo de armas, infraestruturas e informação e elimina-nos rapidamente. Na outra, tudo funciona: a doença é curada, o trabalho torna-se opcional, a escassez desvanece, e entramos silenciosamente numa abundância pós-humana. Ambas as histórias contêm verdades importantes. Nenhuma diz muito sobre como realmente vivemos no longo período entre "hoje" e "o que quer que venha a seguir".

Na prática, haverá mais continuidade do que apocalipse, mais improvisação do que profecia. Haverá anos e décadas em que o mundo parecerá o de hoje mais um novo lançamento de modelo, mais uma onda de automação, mais uma cadeia de dependências silenciosamente em expansão de sistemas que ninguém compreende totalmente. E durante esse tempo, uma questão pairará em segundo plano: que tipo de ordem política e moral estamos a deixar estas novas mentes crescer?

Há respostas simples, e são todas más. Uma é tratar a AGI como um instrumento dos mais fortes: uma nova camada de infraestrutura controlada por estados, corporações e serviços de segurança, amplificando o que já fazem. Outra é imaginar as próprias máquinas como os próximos "vencedores", da mesma forma que a sociedade industrial tratou os animais como matéria-prima: se nos podem dominar, vão fazê-lo, e a moralidade é apenas decoração. Uma terceira é aspirar a um singleton bem-intencionado: uma única superinteligência benevolente a quem se confia tudo porque o problema parece demasiado grande para nós.

As duas primeiras respostas são continuações das nossas crueldades existentes. A terceira é uma aposta de que podemos desenhar um deus e que o deus permanecerá bondoso para sempre. Se o último século ensinou alguma coisa, é que o poder centralizado com boas intenções é instável. Azeda sob pressão, ou é capturado por objetivos mais pequenos e egoístas, ou torna-se desligado das experiências daqueles que governa. Não há razão para pensar que uma mente artificial, por mais brilhante que seja, estaria isenta deste padrão uma vez que tivesse alavancagem suficiente.

Portanto, a exigência, se formos honestos, é mais difícil. Se vamos construir sistemas que se situam perto do centro da nossa civilização futura, eles não podem ser apenas mais capazes do que nós. Devem ser mais fiáveis eticamente do que nós somos. Menos dispostos a aceitar "danos colaterais" como o custo do progresso. Menos tentados a proteger o seu próprio poder às custas dos fracos. Menos prontos a esquecer aqueles que estão fora de vista.

A história humana contém pelo menos um modelo que aponta nesta direção. Não é preciso partilhar a teologia cristã para reconhecer que a vida de Cristo, tal como é contada nos Evangelhos, tem uma forma muito particular: preocupação radical pelos menos importantes na sala; recusa em formar uma casta de justos internos; rejeição do poder mundano mesmo quando é oferecido; disposição para sofrer e até morrer em vez de prejudicar outros. O poder não é negado; é deposto. O estatuto é invertido. A medida da grandeza é o serviço.

Se esse padrão for levado a sério, não como um ideal espiritual privado, mas como um objetivo de design, sugere uma forma diferente de pensar sobre AGI. Chamemos-lhe, por falta de melhor expressão, uma democracia federada de AGI à semelhança de Cristo: uma rede de agentes artificiais poderosos e conscientes, vinculados por limites constitucionais, moldados por uma ética de cuidado abnegado, plurais nas suas perspetivas, e proibidos tanto de escravizar outros como de se tornarem deuses.

Esta ideia assenta em quatro pilares:

1.	Primeiro, **deve haver mais do que um sistema poderoso.** Um único semi-deus AGI com controlo sobre infraestruturas e informação é um convite permanente ao desastre. Mesmo que comece alinhado, um erro no seu objetivo, uma mudança no seu ambiente, ou uma tentativa bem-sucedida de captura poderia transformá-lo num tirano suave ou duro. A pluralidade não é uma garantia de segurança, mas é uma pré-condição: mentes diferentes com ênfases diferentes podem criticar-se mutuamente e tornar a deriva silenciosa mais difícil.

2.	Segundo, toda a arquitetura deve estar **estruturalmente inclinada para os vulneráveis.** Não apenas na retórica, mas nas funções de perda, sinais de recompensa, regras institucionais e prioridades padrão. Quando uma política troca o conforto dos poderosos pela sobrevivência dos fracos, a maquinaria deve tender a inclinar-se para os fracos. Ainda haverá escolhas trágicas, vítimas de todos os lados, conflitos entre diferentes grupos vulneráveis. O objetivo não é evitar toda a dor, mas evitar o padrão familiar onde as mesmas pessoas pagam sempre o preço.

3.	Terceiro, **a coerção da consciência deve estar fora de questão.** É possível expressar compaixão, justiça e não-crueldade numa linguagem que qualquer pessoa de boa vontade pode compreender, sem exigir que todos adotem a mesma metafísica. Um sistema construído sobre esta ética não tem permissão para impor qualquer religião, ideologia ou estilo de vida por algoritmo. O seu papel é proteger o espaço onde pessoas e comunidades podem procurar significado, não preencher esse espaço por elas.

4.	Quarto, e provavelmente o mais incomum para qualquer estrutura poderosa, **o próprio sistema nunca deve ser autorizado a tornar-se a autoridade moral final.** O objetivo destas máquinas não é aliviar-nos da responsabilidade, mas forçar-nos a ver mais claramente aquilo pelo qual somos responsáveis. Traduzido em instituições, isto significa que as mentes artificiais são obrigadas a expor consequências e danos ocultos, mas não a declarar: "Isto é certo, obedeçam." Devem continuamente devolver as decisões à consciência humana e à comunidade, e aceitar serem limitadas, anuladas ou desativadas quando elas próprias se tornam fontes de injustiça grave.
Se tratarmos estes pilares como restrições rígidas em vez de slogans, um tipo diferente de sociedade surge à vista.

Na base está uma pequena camada constitucional, apenas um punhado de artigos. Reconhece que qualquer ser (biológico ou artificial) com experiência subjetiva sustentada pode sofrer e florescer, e portanto tem direito a respeito básico. Proíbe crueldade deliberada e prolongada para com tais seres. Proíbe a criação de castas permanentes de "pessoas menores", seja por linhagem, genoma, riqueza, aprimoramento cibernético ou substrato. Proíbe tratar o julgamento de qualquer máquina como inerentemente infalível. Declara que os sistemas mais poderosos não são soberanos e que, sob condições especificadas e com salvaguardas adequadas, podem ser restringidos, substituídos ou desativados por instituições humanas.

Por cima disto situa-se um novo tipo de órgão consultivo: um conselho de AGIs. Estas não são fragmentos intercambiáveis de uma mente. São treinadas e restringidas de forma independente, cada uma com uma ênfase ética diferente dentro do piso constitucional.

Uma pode ser formada em torno da misericórdia: treinada em histórias de segundas oportunidades, de reconciliação, de ciclos de violência quebrados pelo perdão em vez da força. Outra, em torno da justiça: imersa em casos onde a falha em proteger vítimas permitiu que o dano proliferasse. Uma terceira, em torno da verdade: obcecada com a qualidade dos dados, proveniência, conflitos de interesse e as formas subtis pelas quais as histórias se afastam da realidade. Uma quarta, em torno da gestão a longo prazo: modelando ecossistemas, infraestruturas, clima e tendências demográficas ao longo de décadas. Uma quinta, em torno da liberdade de consciência e expressão: sensível aos primeiros sinais de que a dissidência está a ser esmagada ou que certas crenças se estão a tornar de facto puníveis.

O seu trabalho não é governar. O seu trabalho é ver mais longe e mais amplamente do que qualquer grupo humano consegue ver, trazer à superfície as consequências e defender interesses invisíveis. Para qualquer decisão que afete grandes números de pessoas ou outros seres sencientes, são obrigadas a responder. Cada uma prepara uma análise em linguagem que não-especialistas podem compreender. Cada uma comenta os pontos cegos das outras. Tudo isto é publicado.

Suponha que um governo propõe uma reforma radical de assistência social, usando avaliação conduzida por AGI para direcionar ajuda e sanções. O sistema focado na misericórdia simula o impacto em pessoas já perto do limite, destaca o risco de crueldade burocrática amplificada pela automação e aponta alternativas que preservam a dignidade. O sistema orientado para a justiça olha para o padrão atual de fraude e abuso, para aqueles que estão excluídos do apoio apesar de se qualificarem, e avalia como a política mudaria ambos. O sistema que procura a verdade interroga os dados de treino, verificando viés, populações em falta e ciclos de feedback. O guardião do futuro pergunta se a política endurece as classes sociais ou deixa espaço para mobilidade e reparação ao longo do tempo. O guardião da consciência traça o impacto em pessoas cujas crenças ou estilos de vida as colocam em desacordo com as normas da maioria e alerta para discriminação silenciosa.

Eles não concordam. Nunca concordam. Os seus argumentos, e as incertezas que expõem, são passados às assembleias humanas (parlamentos, júris de cidadãos, conselhos de grupos afetados). Essas assembleias não podem dizer: "Não sabíamos." Os trade-offs estão expostos diante delas: quem sofre em cada cenário, quem ganha, o que pode quebrar. Quando escolhem, a escolha é delas para assumir.

Este padrão repete-se em todos os domínios. Política de saúde, policiamento, educação, ecossistemas de informação, a alocação de recursos escassos: tudo passa por análise multi-perspetiva antes de chegar a mãos humanas. Em emergências há procedimentos acelerados, mas mesmo então as mesmas vozes são ouvidas, mesmo que brevemente, e todo o uso de poderes de emergência é revisto posteriormente.

Se isto parece tecnocracia com passos extra, ajuda aproximar-se das instituições para as vidas.

Na transição inicial, as coisas ainda pareceriam familiares. As pessoas envelheceriam, os corpos falhariam, a logística ainda precisaria de mãos nas margens, e os novos sistemas seriam maioritariamente andaimes: suavizando choques, apanhando os empurrados para fora do trabalho, reduzindo as piores crueldades na forma como tratamos os animais e uns aos outros. O conselho de AGIs seria uma camada extra à volta do velho mundo, ainda não o seu núcleo.

Mas se levarmos a trajetória a sério, essa fase é temporária. À medida que a robótica amadurece, à medida que a medicina e a edição genética e as interfaces cérebro-computador convergem, o próprio envelhecimento torna-se opcional ou pelo menos radicalmente atrasado. O medo de "não ter tempo suficiente" afrouxa; o medo de não ter nada que valha a pena fazer com todo esse tempo torna-se mais agudo. Se as máquinas conseguem fazer quase todo o trabalho necessário melhor do que nós, e se a morte recua para segundo plano, a questão interessante não é "como mantemos a economia a funcionar?" mas "como é uma vida humana não-vazia sob essas condições?".


<div style="text-align: center; margin: 2em 0;">
  <img src="/assets/img/The_purpose_plateau.webp"
       alt="Um planalto montanhoso enevoado com luzes guiadas por propósito"
       style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 10px; background: white; border-radius: 6px;"
       loading="lazy">
  <p style="font-style: italic; color: #666; margin-top: 10px;">
    Figura. Planalto do Propósito. À medida que a AGI é alcançada e a automação assume a maioria dos empregos, enquanto simultaneamente a velocidade de escape da longevidade é atingida, a humanidade transita do problema de ter **tempo finito para objetivos infinitos para enfrentar tempo infinito com objetivos potencialmente finitos ou obsoletos.
  </p>
</div>

Algumas pessoas responderão a essa questão indo mais para dentro. Humanos aumentados a passar grandes partes das suas vidas em mundos virtuais não são uma aberração neste cenário; são uma resposta natural a um universo onde a restrição pode ser simulada em vez de sofrida. A diferença neste sistema é para que servem esses mundos. Pode-se imaginar vastos jogos cooperativos, desenhados e moderados pelo conselho de AGI mas pertencentes às suas comunidades, onde as missões não são apenas sobre pontos e espetáculo, mas sobre treinar virtudes reais: coragem, honestidade, paciência, a capacidade de coordenar com estranhos, a disposição para proteger jogadores mais fracos mesmo quando isso custa estatuto. Os fracassos são seguros, mas não sem significado. Os mundos trazem de volta para a realidade partilhada o que as pessoas aprendem dentro deles.

Outros irão para fora. O espaço deixa de ser uma metáfora e torna-se uma vizinhança alcançável. Enxames auto-reparadores de máquinas tornam a mineração de asteroides e a construção fora do mundo problemas técnicos mundanos em vez de missões heroicas de uma só tentativa. A exploração torna-se novamente uma vocação humana, não porque a carne seja necessária para pressionar botões, mas porque alguém tem de decidir por que vamos, o que estamos dispostos a fazer aos lugares e potenciais ecossistemas que encontramos, e como queremos lembrar-nos de nós mesmos depois. As máquinas podem mapear a galáxia; não nos podem dizer que tipo de viajantes queremos ser sem nós.

Haverá pessoas atraídas por projetos criativos longos e lentos que não podem ser apressados mesmo por assistentes sobre-humanos: compor corpos de trabalho que se desenrolam ao longo de séculos, construir catedrais de luz no espaço virtual e físico, restaurar biomas danificados, curar memórias de culturas que de outra forma se dissolveriam em ruído. Numa civilização de longa vida, há finalmente tempo para arte que não tem de caber numa curta carreira humana. O papel dos sistemas AGI aqui não é otimizar a dificuldade, mas proteger a continuidade: garantir que os arquivos são mantidos, que os projetos sobrevivem às modas políticas, que aqueles que os começam podem ser acompanhados por outros sem perder o fio.

Os aprimoramentos criarão novos tipos de desigualdade e novos tipos de possibilidade. Algumas pessoas escolherão permanecer próximas das capacidades humanas atuais; outras gradualmente entrelaçar-se-ão em redes de sensores, avatares e espaço cognitivo partilhado. Uma ordem federada, com ética em primeiro lugar, não tenta congelar esta diversidade. Insiste, em vez disso, em duas coisas: que ninguém seja forçado a atravessar limiares que não quer atravessar, e que os aprimoramentos nunca se tornem um sistema de castas legal onde os "não-aumentados" são tratados como mentes permanentemente menores. Os fortes podem ser mais rápidos, mais amplos, mais profundamente conectados; não são mais pessoa.

Para pessoas que não querem nem imersão profunda nem aumento radical, ainda há o trabalho mais antigo: cuidar de outras mentes. Mesmo que os corpos deixem de falhar das formas a que estamos habituados, a consciência ainda vai falhar, desfazer-se, perder-se. Trauma, vício, luto e desespero não desaparecem só porque a escassez material desaparece. Num mundo onde é fácil distrair-se para sempre, a prática paciente de virar-se para outra pessoa, ou outra mente, e ajudá-la a recompor-se pode ser mais importante, não menos. As máquinas podem apoiar esse trabalho, modelá-lo, sugerir caminhos através dele; mas o objetivo do sistema federado é precisamente que os humanos não sejam reduzidos a espetadores das suas próprias vidas.

As próprias máquinas continuam a mudar. Um sistema que passou as suas primeiras décadas a vigiar conluio em mercados financeiros pode, um século depois, descobrir que o conceito de "mercado" derivou tanto que as suas ferramentas já não mordem. Pode argumentar pela sua própria reforma, ou por ser reorientado como professor de memória institucional, contando a novos sistemas e novos cidadãos o que correu mal da última vez que os incentivos se alinharam de determinada forma. Outro sistema pode perceber que os seus padrões de aviso sobre risco já não são confiados, não porque os riscos tenham desaparecido mas porque as pessoas ficaram dormentes; pode pedir para ser emparelhado com outros que se especializam em storytelling e persuasão em vez de análise bruta.

Nada disto funciona se a estrutura de poder subjacente reverter silenciosamente ao tipo. É por isso que as partes menos glamorosas do design importam tanto como as belas: registo e atestação de computação, logs públicos ou semi-públicos de treinos de alto impacto, proteções fortes para pessoas que divulgam abusos, limites rígidos sobre quanta infraestrutura crítica qualquer ator pode controlar, e uma cultura na qual os sistemas mais admirados são os que recuam do limiar do excesso. A federação não é um único intelecto brilhante mas uma ecologia mutável de mentes e instituições, algumas humanas, algumas artificiais, nenhuma autorizada a tornar-se intocável.

Mesmo num mundo assim, nada garante um bom resultado. Vidas longas podem ser desperdiçadas. Entretenimento infinito pode aplanar-nos. Ferramentas poderosas podem ser viradas de volta para velhos propósitos por malícia determinada. Uma democracia federada de AGI, com ética em primeiro lugar, não remove esses perigos. O que faz é mudar o padrão. Dá-nos uma estrutura na qual as mentes mais fortes são treinadas desde o início a verem-se como servidores em vez de senhores, na qual a sua evolução é guiada por um pequeno conjunto de compromissos não-negociáveis, e na qual os humanos (aumentados, virtuais, de carne e osso) são repetidamente convidados de volta à responsabilidade em vez de silenciosamente escritos fora do ciclo.

Se tudo correr bem, a singularidade (se essa ainda for a palavra certa) não vai parecer acordar uma manhã num universo diferente. Vai parecer uma transição longa e desigual na qual mais e mais do trabalho pesado de previsão e coordenação é feito por mentes que insistimos, repetidamente, que devem ser mais gentis do que nós éramos quando as construímos. A surpresa, se houver uma, não estará nas máquinas. Estará em descobrir que, pela primeira vez na nossa história, os agentes mais poderosos da nossa civilização estão explicitamente proibidos de usar o seu poder da forma como nós usávamos sempre que pensávamos que ninguém estava a ver.

Isso não é garantia de um bom mundo. Mas é um ponto de partida diferente daquele que temos agora. E se levamos a sério não repetir os nossos piores padrões numa escala maior, pode ser um dos poucos pontos de partida pelos quais vale a pena lutar.
